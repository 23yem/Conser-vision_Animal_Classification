{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default code from Kaggle Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "   \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames: \n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying some important libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(\"Tensorflow:\", tf.__version__)\n",
    "\n",
    "# import kerastuner as kt\n",
    "# print(\"kerastuner:\", kt.__version__)\n",
    "\n",
    "# import keras_tuner as kt2\n",
    "# print(\"keras_tuner:\", kt2.__version__)\n",
    "\n",
    "# import platform\n",
    "# print(\"Python:\", platform.python_version())\n",
    "\n",
    "# import numpy as np\n",
    "# print(\"numpy:\", np.__version__)\n",
    "\n",
    "# import pandas as pd\n",
    "# print(\"pandas:\", pd.__version__)\n",
    "\n",
    "# import sklearn\n",
    "# print(\"sklearn version:\", sklearn.__version__)\n",
    "\n",
    "# import sklearn\n",
    "# print(\"sklearn path:\", sklearn.__path__)\n",
    "\n",
    "# import matplotlib\n",
    "# print(\"matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "# import seaborn as sns\n",
    "# print(\"seaborn:\", sns.__version__)\n",
    "\n",
    "# # On WSL\n",
    "\n",
    "# # 2024-01-30 11:17:52.768682: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
    "# # 2024-01-30 11:17:53.149956: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "# # 2024-01-30 11:17:53.150001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "# # 2024-01-30 11:17:53.210606: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "# # 2024-01-30 11:17:53.339576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "# # To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "# # 2024-01-30 11:17:54.568146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "# # Tensorflow: 2.15.0\n",
    "# # /tmp/ipykernel_3814/2917868046.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
    "# #   import kerastuner as kt\n",
    "# # kerastuner: 1.0.5\n",
    "# # keras_tuner: 1.3.5\n",
    "# # Python: 3.10.12\n",
    "# # numpy: 1.24.3\n",
    "# # pandas: 2.1.4\n",
    "# # sklearn version: 1.2.2\n",
    "# # sklearn path: ['/home/michaelye22/.local/lib/python3.10/site-packages/sklearn']\n",
    "# # matplotlib: 3.8.2\n",
    "# # seaborn: 0.13.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global random seed to make sure we can replicate any model that we create (no randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 11:50:12.053835: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-10 11:50:12.312447: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 11:50:12.313440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 11:50:12.333466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-10 11:50:12.464960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 11:50:14.160619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use TPU instead of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    raise BaseException('ERROR: Not connected to a TPU runtime!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.TPUStrategy(tpu)  # Updated to the non-experimental version\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_values are the features (X), and train_labels is the target/label (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"train_features.csv\")\n",
    "train_y = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "test_values = pd.read_csv(\"test_features.csv\")\n",
    "\n",
    "# print(\"train labels:\\n\", train_Y.head())\n",
    "\n",
    "# print(\"train values:\\n\", train_X.head())\n",
    "      \n",
    "# print(\"test_values:\\n\", test_values.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if there are any missing values in the data. If so, we have to do imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in train_X: 0\n",
      "Number of missing values in train_Y: 0\n",
      "Number of missing values in test_values: 0\n"
     ]
    }
   ],
   "source": [
    "missing_train_X = train_X.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_X:\", missing_train_X)\n",
    "\n",
    "missing_train_y = train_y.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_Y:\", missing_train_y)\n",
    "\n",
    "missing_test_values = test_values.isnull().sum().sum()\n",
    "print(\"Number of missing values in test_values:\", missing_test_values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 0 missing values in each dataframe, we don't have to do imputation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Train Distribution  Validation Distribution  \\\n",
      "site_animal                                                           \n",
      "S0001_bird                        0.000692                 0.000813   \n",
      "S0001_blank                       0.000346                 0.000407   \n",
      "S0001_leopard                     0.003112                 0.002847   \n",
      "S0001_monkey_prosimian            0.001037                 0.001220   \n",
      "S0002_bird                        0.000519                 0.000813   \n",
      "\n",
      "                        Test Distribution  \n",
      "site_animal                                \n",
      "S0001_bird                       0.000407  \n",
      "S0001_blank                      0.000407  \n",
      "S0001_leopard                    0.003252  \n",
      "S0001_monkey_prosimian           0.000813  \n",
      "S0002_bird                       0.000407  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "\n",
    "train_features = train_X\n",
    "train_labels = train_y\n",
    "\n",
    "# Merge the datasets on 'id'\n",
    "merged_data = pd.merge(train_features, train_labels, on='id')\n",
    "\n",
    "# Identifying the animal present in each image and creating a combined category\n",
    "animal_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "merged_data['animal'] = merged_data[animal_columns].idxmax(axis=1)\n",
    "merged_data['site_animal'] = merged_data['site'] + '_' + merged_data['animal']\n",
    "\n",
    "# Checking the number of instances for each site_animal combination\n",
    "combination_counts = merged_data['site_animal'].value_counts()\n",
    "rare_combinations = combination_counts[combination_counts < 5]\n",
    "\n",
    "# Separating the dataset into common and rare combinations\n",
    "common_combinations = merged_data[~merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "rare_combinations_data = merged_data[merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "\n",
    "\n",
    "\n",
    "# Stratified split for common combinations into train and temp sets\n",
    "common_train_set, common_temp_set = train_test_split(\n",
    "    common_combinations, test_size=0.3, stratify=common_combinations['site_animal'], random_state=42)\n",
    "\n",
    "# Check if each class has at least two instances\n",
    "class_counts = common_temp_set['site_animal'].value_counts()\n",
    "single_instance_classes = class_counts[class_counts < 2]\n",
    "\n",
    "# Separate single instance classes\n",
    "single_instance_data = common_temp_set[common_temp_set['site_animal'].isin(single_instance_classes.index)]\n",
    "common_temp_set = common_temp_set[~common_temp_set['site_animal'].isin(single_instance_classes.index)]\n",
    "\n",
    "# Stratified split for common combinations into validation and test sets\n",
    "common_val_set, common_test_set = train_test_split(\n",
    "    common_temp_set, test_size=0.5, stratify=common_temp_set['site_animal'], random_state=42)\n",
    "\n",
    "# Add single instance classes to the training set\n",
    "common_train_set = pd.concat([common_train_set, single_instance_data])\n",
    "\n",
    "\n",
    "\n",
    "# Randomly splitting rare combinations into train and temp sets\n",
    "total_samples = rare_combinations_data.shape[0]\n",
    "train_samples = int(np.round(total_samples * 0.7))\n",
    "rare_train_set = rare_combinations_data.sample(n=train_samples, random_state=42)\n",
    "rare_temp_set = rare_combinations_data.drop(rare_train_set.index)\n",
    "\n",
    "# Randomly splitting rare combinations into validation and test sets\n",
    "total_samples = rare_temp_set.shape[0]\n",
    "val_samples = int(np.round(total_samples * 0.5))\n",
    "rare_val_set = rare_temp_set.sample(n=val_samples, random_state=42)\n",
    "rare_test_set = rare_temp_set.drop(rare_val_set.index)\n",
    "\n",
    "# Combining the splits into final train, validation and test sets\n",
    "final_train_set = pd.concat([common_train_set, rare_train_set])\n",
    "final_val_set = pd.concat([common_val_set, rare_val_set])\n",
    "final_test_set = pd.concat([common_test_set, rare_test_set])\n",
    "\n",
    "# Optional: Verifying the final distribution (can be commented out for large datasets)\n",
    "final_train_distribution = final_train_set['site_animal'].value_counts(normalize=True)\n",
    "final_val_distribution = final_val_set['site_animal'].value_counts(normalize=True)\n",
    "final_test_distribution = final_test_set['site_animal'].value_counts(normalize=True)\n",
    "final_distribution_summary = pd.DataFrame({\n",
    "    'Train Distribution': final_train_distribution,\n",
    "    'Validation Distribution': final_val_distribution,\n",
    "    'Test Distribution': final_test_distribution\n",
    "})\n",
    "print(final_distribution_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load the datasets\n",
    "\n",
    "# train_features = train_X\n",
    "# train_labels = train_y\n",
    "\n",
    "# # Merge the datasets on 'id'\n",
    "# merged_data = pd.merge(train_features, train_labels, on='id')\n",
    "\n",
    "# # Identifying the animal present in each image and creating a combined category\n",
    "# animal_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "# merged_data['animal'] = merged_data[animal_columns].idxmax(axis=1)\n",
    "# merged_data['site_animal'] = merged_data['site'] + '_' + merged_data['animal']\n",
    "\n",
    "# # Checking the number of instances for each site_animal combination\n",
    "# combination_counts = merged_data['site_animal'].value_counts()\n",
    "# rare_combinations = combination_counts[combination_counts < 5]\n",
    "\n",
    "# # Separating the dataset into common and rare combinations\n",
    "# common_combinations = merged_data[~merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "# rare_combinations_data = merged_data[merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "\n",
    "# # Stratified split for common combinations into train and temp sets\n",
    "# common_train_set, common_temp_set = train_test_split(\n",
    "#     common_combinations, test_size=0.3, stratify=common_combinations['site_animal'], random_state=42)\n",
    "\n",
    "# # Stratified split for common combinations into validation and test sets\n",
    "# common_val_set, common_test_set = train_test_split(\n",
    "#     common_temp_set, test_size=0.5, stratify=common_temp_set['site_animal'], random_state=42)\n",
    "\n",
    "# # Randomly splitting rare combinations into train and temp sets\n",
    "# total_samples = rare_combinations_data.shape[0]\n",
    "# train_samples = int(np.round(total_samples * 0.7))\n",
    "# rare_train_set = rare_combinations_data.sample(n=train_samples, random_state=42)\n",
    "# rare_temp_set = rare_combinations_data.drop(rare_train_set.index)\n",
    "\n",
    "# # Randomly splitting rare combinations into validation and test sets\n",
    "# total_samples = rare_temp_set.shape[0]\n",
    "# val_samples = int(np.round(total_samples * 0.5))\n",
    "# rare_val_set = rare_temp_set.sample(n=val_samples, random_state=42)\n",
    "# rare_test_set = rare_temp_set.drop(rare_val_set.index)\n",
    "\n",
    "# # Combining the splits into final train, validation and test sets\n",
    "# final_train_set = pd.concat([common_train_set, rare_train_set])\n",
    "# final_val_set = pd.concat([common_val_set, rare_val_set])\n",
    "# final_test_set = pd.concat([common_test_set, rare_test_set])\n",
    "\n",
    "# # Optional: Verifying the final distribution (can be commented out for large datasets)\n",
    "# final_train_distribution = final_train_set['site_animal'].value_counts(normalize=True)\n",
    "# final_val_distribution = final_val_set['site_animal'].value_counts(normalize=True)\n",
    "# final_test_distribution = final_test_set['site_animal'].value_counts(normalize=True)\n",
    "# final_distribution_summary = pd.DataFrame({\n",
    "#     'Train Distribution': final_train_distribution,\n",
    "#     'Validation Distribution': final_val_distribution,\n",
    "#     'Test Distribution': final_test_distribution\n",
    "# })\n",
    "# print(final_distribution_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load the datasets\n",
    "\n",
    "# train_features = train_X\n",
    "# train_labels = train_y\n",
    "\n",
    "# # Merge the datasets on 'id'\n",
    "# merged_data = pd.merge(train_features, train_labels, on='id')\n",
    "\n",
    "# # Identifying the animal present in each image and creating a combined category\n",
    "# animal_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "# merged_data['animal'] = merged_data[animal_columns].idxmax(axis=1)\n",
    "# merged_data['site_animal'] = merged_data['site'] + '_' + merged_data['animal']\n",
    "\n",
    "# # Checking the number of instances for each site_animal combination\n",
    "# combination_counts = merged_data['site_animal'].value_counts()\n",
    "# rare_combinations = combination_counts[combination_counts < 5]\n",
    "\n",
    "# # Separating the dataset into common and rare combinations\n",
    "# common_combinations = merged_data[~merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "# rare_combinations_data = merged_data[merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "\n",
    "# # Stratified split for common combinations\n",
    "# common_train_set, common_test_set = train_test_split(\n",
    "#     common_combinations, test_size=0.25, stratify=common_combinations['site_animal'], random_state=42)\n",
    "\n",
    "# # Randomly splitting rare combinations\n",
    "# total_samples = rare_combinations_data.shape[0]\n",
    "# train_samples = int(np.round(total_samples * 0.75))\n",
    "# rare_train_set = rare_combinations_data.sample(n=train_samples, random_state=42)\n",
    "# rare_test_set = rare_combinations_data.drop(rare_train_set.index)\n",
    "\n",
    "# # Combining the splits into final train and test sets\n",
    "# final_train_set = pd.concat([common_train_set, rare_train_set])\n",
    "# final_test_set = pd.concat([common_test_set, rare_test_set])\n",
    "\n",
    "# # Optional: Verifying the final distribution (can be commented out for large datasets)\n",
    "# final_train_distribution = final_train_set['site_animal'].value_counts(normalize=True)\n",
    "# final_test_distribution = final_test_set['site_animal'].value_counts(normalize=True)\n",
    "# final_distribution_summary = pd.DataFrame({\n",
    "#     'Train Distribution': final_train_distribution,\n",
    "#     'Test Distribution': final_test_distribution\n",
    "# })\n",
    "# print(final_distribution_summary.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Verify the 75/25 train_test split\n",
    "\n",
    "# # Calculate the number of samples in each set\n",
    "# num_train_samples = final_train_set.shape[0]\n",
    "# num_test_samples = final_test_set.shape[0]\n",
    "# total_samples = num_train_samples + num_test_samples\n",
    "\n",
    "# # Calculate the proportions\n",
    "# train_proportion = num_train_samples / total_samples\n",
    "# test_proportion = num_test_samples / total_samples\n",
    "\n",
    "# # Print out the proportions\n",
    "# print(\"Training Set Proportion: {:.2%}\".format(train_proportion))\n",
    "# print(\"Test Set Proportion: {:.2%}\".format(test_proportion))\n",
    "\n",
    "\n",
    "\n",
    "# ## Making sure that train and test set have a 75/25 split for each site\n",
    "\n",
    "\n",
    "# # Calculate the count of each site in both sets\n",
    "# site_counts_train = final_train_set['site'].value_counts()\n",
    "# site_counts_test = final_test_set['site'].value_counts()\n",
    "\n",
    "# # Combine the counts into a single DataFrame for comparison\n",
    "# combined_site_counts = pd.DataFrame({'Train Count': site_counts_train, 'Test Count': site_counts_test})\n",
    "\n",
    "# # Calculate the total counts for each site\n",
    "# combined_site_counts['Total Count'] = combined_site_counts['Train Count'] + combined_site_counts['Test Count']\n",
    "\n",
    "# # Calculate the percentage split for each site\n",
    "# combined_site_counts['Train Percentage'] = (combined_site_counts['Train Count'] / combined_site_counts['Total Count']) * 100\n",
    "# combined_site_counts['Test Percentage'] = (combined_site_counts['Test Count'] / combined_site_counts['Total Count']) * 100\n",
    "\n",
    "# # Display the combined counts with percentage split\n",
    "# #print(combined_site_counts.head())\n",
    "# combined_site_counts.to_csv(\"site_percentage_check.csv\")\n",
    "\n",
    "# # Check to see if there any rows of data with a train percentage below 70 or above 80 (the ideal is 75)\n",
    "# filtered_df = combined_site_counts[(combined_site_counts['Train Percentage'] < 70) | (combined_site_counts['Train Percentage'] > 80)]\n",
    "# #print(filtered_df)\n",
    "# #print(len(filtered_df)) # There are only 13 sites which have a bad train/test split, but they all side more towards the train set, which is good\n",
    "\n",
    "\n",
    "# #print(len(final_train_set))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Making sure the trian and test set have the 75/25 split for each animal \n",
    "# # List of label columns\n",
    "# label_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "\n",
    "# # Calculate the count of each label in both sets\n",
    "# label_counts_train = final_train_set[label_columns].sum()\n",
    "# label_counts_test = final_test_set[label_columns].sum()\n",
    "\n",
    "# # Combine the counts into a single DataFrame for comparison\n",
    "# combined_label_counts = pd.DataFrame({'Train Count': label_counts_train, 'Test Count': label_counts_test})\n",
    "\n",
    "# # Calculate the total counts for each label\n",
    "# combined_label_counts['Total Count'] = combined_label_counts['Train Count'] + combined_label_counts['Test Count']\n",
    "\n",
    "# # Calculate the percentage split for each label\n",
    "# combined_label_counts['Train Percentage'] = (combined_label_counts['Train Count'] / combined_label_counts['Total Count']) * 100\n",
    "# combined_label_counts['Test Percentage'] = (combined_label_counts['Test Count'] / combined_label_counts['Total Count']) * 100\n",
    "\n",
    "# # Display the combined counts with percentage split\n",
    "# #print(combined_label_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Modifying the data to include only the original columns\n",
    "\n",
    "# #print(final_train_set)\n",
    "\n",
    "# # Remove all the new features that I created for the stratified train_test split\n",
    "# train_X = final_train_set[['id', 'filepath', 'site']]\n",
    "# train_Y = final_train_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "# test_X = final_test_set[['id', 'filepath', 'site']]\n",
    "# test_Y = final_test_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "\n",
    "# # Make \"id\" the index column\n",
    "# train_X.set_index('id', inplace=True) # inplace = True means that it edits the original dataframe, and no new dataframe is created\n",
    "# train_Y.set_index('id', inplace=True)\n",
    "\n",
    "# test_X.set_index('id', inplace=True)\n",
    "# test_Y.set_index('id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Make it so that if there already exists a dataset for train_X, train_Y, and test_X, then we will use those (so that each of my models are trained on the same data, making them deterministic)\n",
    "# import os\n",
    "\n",
    "# if not os.path.exists('train_split_X.csv'):\n",
    "#     print(\"create new directory\")\n",
    "#     train_X.to_csv('train_split_X.csv')\n",
    "#     train_Y.to_csv('train_split_Y.csv')\n",
    "#     test_X.to_csv('test_split_X.csv')\n",
    "#     test_Y.to_csv('test_split_Y.csv')\n",
    "\n",
    "# else:\n",
    "#     print(\"used old directory\")\n",
    "#     train_X = pd.read_csv('train_split_X.csv')\n",
    "#     train_Y = pd.read_csv('train_split_Y.csv')\n",
    "#     test_X = pd.read_csv('test_split_X.csv')\n",
    "#     test_Y = pd.read_csv(\"test_split_Y.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the 75/25 train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Proportion: 70.17%\n",
      "Validation Set Proportion: 14.91%\n",
      "Test Set Proportion: 14.92%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of samples in each set\n",
    "num_train_samples = final_train_set.shape[0]\n",
    "num_val_samples = final_val_set.shape[0]\n",
    "num_test_samples = final_test_set.shape[0]\n",
    "total_samples = num_train_samples + num_val_samples + num_test_samples\n",
    "\n",
    "# Calculate the proportions\n",
    "train_proportion = num_train_samples / total_samples\n",
    "val_proportion = num_val_samples / total_samples\n",
    "test_proportion = num_test_samples / total_samples\n",
    "\n",
    "# Print out the proportions\n",
    "print(\"Training Set Proportion: {:.2%}\".format(train_proportion))\n",
    "print(\"Validation Set Proportion: {:.2%}\".format(val_proportion))\n",
    "print(\"Test Set Proportion: {:.2%}\".format(test_proportion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure that train and test set have a 75/25 split for each site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for each site, around 75% should be in the training data and around 25% should be in the test data. This ensures niether the train or test set have a unbalanced amount of a certain site, leading to bias and bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Train Count  Validation Count  Test Count  Total Count  \\\n",
      "site                                                            \n",
      "S0007            7               1.0         1.0          9.0   \n",
      "S0017           15               2.0         2.0         19.0   \n",
      "S0028           22               5.0         2.0         29.0   \n",
      "S0046            8               1.0         1.0         10.0   \n",
      "S0078            1               1.0         NaN          2.0   \n",
      "S0079            2               NaN         NaN          2.0   \n",
      "S0092            2               NaN         1.0          3.0   \n",
      "S0098            8               2.0         1.0         11.0   \n",
      "S0102            1               NaN         NaN          1.0   \n",
      "S0106            4               NaN         1.0          5.0   \n",
      "S0107            7               NaN         1.0          8.0   \n",
      "S0112            4               NaN         NaN          4.0   \n",
      "S0115            7               1.0         1.0          9.0   \n",
      "S0121           14               5.0         1.0         20.0   \n",
      "S0143            2               1.0         NaN          3.0   \n",
      "S0146           12               5.0         3.0         20.0   \n",
      "S0148            6               1.0         NaN          7.0   \n",
      "S0153            6               1.0         2.0          9.0   \n",
      "S0157           25               4.0         4.0         33.0   \n",
      "S0158           11               NaN         NaN         11.0   \n",
      "S0160           17               2.0         3.0         22.0   \n",
      "S0171           18               2.0         2.0         22.0   \n",
      "S0173           16               4.0         5.0         25.0   \n",
      "S0176           20               3.0         3.0         26.0   \n",
      "S0177           10               3.0         3.0         16.0   \n",
      "S0178            1               1.0         NaN          2.0   \n",
      "S0182            6               3.0         1.0         10.0   \n",
      "S0190            5               NaN         NaN          5.0   \n",
      "S0191            8               2.0         1.0         11.0   \n",
      "S0192            6               NaN         NaN          6.0   \n",
      "S0196           13               1.0         1.0         15.0   \n",
      "S0197           10               4.0         3.0         17.0   \n",
      "\n",
      "       Train Percentage  Validation Percentage  Test Percentage  \n",
      "site                                                             \n",
      "S0007         77.777778              11.111111        11.111111  \n",
      "S0017         78.947368              10.526316        10.526316  \n",
      "S0028         75.862069              17.241379         6.896552  \n",
      "S0046         80.000000              10.000000        10.000000  \n",
      "S0078         50.000000              50.000000              NaN  \n",
      "S0079        100.000000                    NaN              NaN  \n",
      "S0092         66.666667                    NaN        33.333333  \n",
      "S0098         72.727273              18.181818         9.090909  \n",
      "S0102        100.000000                    NaN              NaN  \n",
      "S0106         80.000000                    NaN        20.000000  \n",
      "S0107         87.500000                    NaN        12.500000  \n",
      "S0112        100.000000                    NaN              NaN  \n",
      "S0115         77.777778              11.111111        11.111111  \n",
      "S0121         70.000000              25.000000         5.000000  \n",
      "S0143         66.666667              33.333333              NaN  \n",
      "S0146         60.000000              25.000000        15.000000  \n",
      "S0148         85.714286              14.285714              NaN  \n",
      "S0153         66.666667              11.111111        22.222222  \n",
      "S0157         75.757576              12.121212        12.121212  \n",
      "S0158        100.000000                    NaN              NaN  \n",
      "S0160         77.272727               9.090909        13.636364  \n",
      "S0171         81.818182               9.090909         9.090909  \n",
      "S0173         64.000000              16.000000        20.000000  \n",
      "S0176         76.923077              11.538462        11.538462  \n",
      "S0177         62.500000              18.750000        18.750000  \n",
      "S0178         50.000000              50.000000              NaN  \n",
      "S0182         60.000000              30.000000        10.000000  \n",
      "S0190        100.000000                    NaN              NaN  \n",
      "S0191         72.727273              18.181818         9.090909  \n",
      "S0192        100.000000                    NaN              NaN  \n",
      "S0196         86.666667               6.666667         6.666667  \n",
      "S0197         58.823529              23.529412        17.647059  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the count of each site in all sets\n",
    "site_counts_train = final_train_set['site'].value_counts()\n",
    "site_counts_val = final_val_set['site'].value_counts()\n",
    "site_counts_test = final_test_set['site'].value_counts()\n",
    "\n",
    "# Combine the counts into a single DataFrame for comparison\n",
    "combined_site_counts = pd.DataFrame({'Train Count': site_counts_train, 'Validation Count': site_counts_val, 'Test Count': site_counts_test})\n",
    "\n",
    "# Calculate the total counts for each site\n",
    "combined_site_counts['Total Count'] = combined_site_counts.sum(axis=1)\n",
    "\n",
    "# Calculate the percentage split for each site\n",
    "combined_site_counts['Train Percentage'] = (combined_site_counts['Train Count'] / combined_site_counts['Total Count']) * 100\n",
    "combined_site_counts['Validation Percentage'] = (combined_site_counts['Validation Count'] / combined_site_counts['Total Count']) * 100\n",
    "combined_site_counts['Test Percentage'] = (combined_site_counts['Test Count'] / combined_site_counts['Total Count']) * 100\n",
    "\n",
    "# Display the combined counts with percentage split\n",
    "combined_site_counts.to_csv(\"site_percentage_check.csv\")\n",
    "\n",
    "# Check to see if there any rows of data with a train percentage below 65 or above 75, validation percentage below 10 or above 20, and test percentage below 10 or above 20\n",
    "filtered_df = combined_site_counts[(combined_site_counts['Train Percentage'] < 65) | (combined_site_counts['Train Percentage'] > 75) | (combined_site_counts['Validation Percentage'] < 10) | (combined_site_counts['Validation Percentage'] > 20) | (combined_site_counts['Test Percentage'] < 10) | (combined_site_counts['Test Percentage'] > 20)]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 13 sites which have a bad train/test split, but they all side more towards the train set, which is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure the trian and test set have the 75/25 split for each animal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for each animal, around 75% should be in the training data and around 25% should be in the test data. This ensures neither the train or test set have a unbalanced amount of a certain animal, leading to bias and bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Train Count, Validation Count, Test Count, Total Count, Train Percentage, Validation Percentage, Test Percentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# List of label columns\n",
    "label_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "\n",
    "# Calculate the count of each label in all sets\n",
    "label_counts_train = final_train_set[label_columns].sum()\n",
    "label_counts_val = final_val_set[label_columns].sum()\n",
    "label_counts_test = final_test_set[label_columns].sum()\n",
    "\n",
    "# Combine the counts into a single DataFrame for comparison\n",
    "combined_label_counts = pd.DataFrame({'Train Count': label_counts_train, 'Validation Count': label_counts_val, 'Test Count': label_counts_test})\n",
    "\n",
    "# Calculate the total counts for each label\n",
    "combined_label_counts['Total Count'] = combined_label_counts.sum(axis=1)\n",
    "\n",
    "# Calculate the percentage split for each label\n",
    "combined_label_counts['Train Percentage'] = (combined_label_counts['Train Count'] / combined_label_counts['Total Count']) * 100\n",
    "combined_label_counts['Validation Percentage'] = (combined_label_counts['Validation Count'] / combined_label_counts['Total Count']) * 100\n",
    "combined_label_counts['Test Percentage'] = (combined_label_counts['Test Count'] / combined_label_counts['Total Count']) * 100\n",
    "\n",
    "# Display the combined counts with percentage split\n",
    "combined_label_counts.to_csv(\"label_percentage_check.csv\")\n",
    "\n",
    "# Check to see if there any rows of data with a train percentage below 65 or above 75, validation percentage below 10 or above 20, and test percentage below 10 or above 20\n",
    "filtered_df = combined_label_counts[(combined_label_counts['Train Percentage'] < 65) | (combined_label_counts['Train Percentage'] > 75) | (combined_label_counts['Validation Percentage'] < 10) | (combined_label_counts['Validation Percentage'] > 20) | (combined_label_counts['Test Percentage'] < 10) | (combined_label_counts['Test Percentage'] > 20)]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each class has around a 75/25 split for train and test split, my data looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the data to include only the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             filepath   site\n",
      "id                                          \n",
      "ZJ015450  train_features/ZJ015450.jpg  S0003\n",
      "ZJ009090  train_features/ZJ009090.jpg  S0150\n",
      "ZJ007499  train_features/ZJ007499.jpg  S0085\n",
      "ZJ010855  train_features/ZJ010855.jpg  S0062\n",
      "ZJ012846  train_features/ZJ012846.jpg  S0002\n",
      "...                               ...    ...\n",
      "ZJ011873  train_features/ZJ011873.jpg  S0134\n",
      "ZJ008591  train_features/ZJ008591.jpg  S0179\n",
      "ZJ002311  train_features/ZJ002311.jpg  S0121\n",
      "ZJ006934  train_features/ZJ006934.jpg  S0050\n",
      "ZJ014065  train_features/ZJ014065.jpg  S0185\n",
      "\n",
      "[11569 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove all the new features that I created for the stratified train_test split\n",
    "train_X = final_train_set[['id', 'filepath', 'site']]\n",
    "train_Y = final_train_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "valid_X = final_val_set[['id', 'filepath', 'site']]\n",
    "valid_Y = final_val_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "test_X = final_test_set[['id', 'filepath', 'site']]\n",
    "test_Y = final_test_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "# Make \"id\" the index column\n",
    "train_X.set_index('id', inplace=True) # inplace = True means that it edits the original dataframe, and no new dataframe is created\n",
    "train_Y.set_index('id', inplace=True)\n",
    "\n",
    "valid_X.set_index('id', inplace=True)\n",
    "valid_Y.set_index('id', inplace=True)\n",
    "\n",
    "test_X.set_index('id', inplace=True)\n",
    "test_Y.set_index('id', inplace=True)\n",
    "\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it so that if there already exists a dataset for train_X, train_Y, and test_X, then we will use those (so that each of my models are trained on the same data, making them deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used old directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('train_split_2_X.csv'):\n",
    "    print(\"create new directory\")\n",
    "    train_X.to_csv('train_split_2_X.csv')\n",
    "    train_Y.to_csv('train_split_2_Y.csv')\n",
    "    valid_X.to_csv('valid_split_2_X.csv')\n",
    "    valid_Y.to_csv('valid_split_2_Y.csv')\n",
    "    test_X.to_csv('test_split_2_X.csv')\n",
    "    test_Y.to_csv('test_split_2_Y.csv')\n",
    "\n",
    "else:\n",
    "    print(\"used old directory\")\n",
    "    train_X = pd.read_csv('train_split_2_X.csv', index_col='id')\n",
    "    train_Y = pd.read_csv('train_split_2_Y.csv', index_col='id')\n",
    "    valid_X = pd.read_csv('valid_split_2_X.csv', index_col='id')\n",
    "    valid_Y = pd.read_csv('valid_split_2_Y.csv', index_col='id')\n",
    "    test_X = pd.read_csv('test_split_2_X.csv', index_col='id')\n",
    "    test_Y = pd.read_csv(\"test_split_2_Y.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if each image has the same dimensions since that's important for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# def check_image_dimensions(directory):\n",
    "#     image_sizes = {}\n",
    "#     for img_name in os.listdir(directory):\n",
    "#         if not img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')): # now also checks for .tif\n",
    "#             continue\n",
    "#         img_path = os.path.join(directory, img_name)\n",
    "#         with Image.open(img_path) as img:\n",
    "#             # Get image size\n",
    "#             size = img.size\n",
    "#             if size in image_sizes:\n",
    "#                 image_sizes[size] += 1\n",
    "#             else:\n",
    "#                 image_sizes[size] = 1\n",
    "\n",
    "#     for size, count in image_sizes.items():\n",
    "#         print(f\"For the {directory} directory, {count} images are of dimension {size}\")\n",
    "\n",
    "# # Use it on the train and test data only if this code segment was never ran in this coding session:\n",
    "\n",
    "# # Use it on the train and test data:\n",
    "# check_image_dimensions('train_features')\n",
    "# check_image_dimensions('test_features')\n",
    "\n",
    "\n",
    "# # # For the train_features directory, different dimensions found: {(160, 120), (960, 515), (640, 335), (960, 540), (640, 360), (360, 215), (160, 95), (360, 240)}\n",
    "# # # For the test_features directory, different dimensions found: {(960, 515), (160, 120), (640, 335), (960, 540), (320, 215), (640, 360), (360, 240), (320, 240)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing all the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will actually make the resizing function when I use the ImageDataGenertor. \n",
    "# By calling the resize function in the ImageDataGenerator, I won't have to save my images in my local folder and waste space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before I use ImageDataGenerator, I have to format my dataframes so that they are able to be read properly by ImageDataGenertor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multi-class problem so data format has to be modified so that it can be handled by ImageDataGenerator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'id' does not exist in merged_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'id' does not exist in merged_train\n",
      "Column 'id' does not exist in merged_train\n",
      "                             filepath   site  antelope_duiker  bird  blank  \\\n",
      "id                                                                           \n",
      "ZJ006365  train_features/ZJ006365.jpg  S0062              0.0   0.0    0.0   \n",
      "ZJ008401  train_features/ZJ008401.jpg  S0120              0.0   0.0    1.0   \n",
      "ZJ015840  train_features/ZJ015840.jpg  S0014              0.0   0.0    0.0   \n",
      "ZJ004201  train_features/ZJ004201.jpg  S0071              0.0   0.0    0.0   \n",
      "ZJ014267  train_features/ZJ014267.jpg  S0014              1.0   0.0    0.0   \n",
      "...                               ...    ...              ...   ...    ...   \n",
      "ZJ015318  train_features/ZJ015318.jpg  S0134              0.0   0.0    0.0   \n",
      "ZJ015363  train_features/ZJ015363.jpg  S0176              0.0   0.0    0.0   \n",
      "ZJ015565  train_features/ZJ015565.jpg  S0124              0.0   1.0    0.0   \n",
      "ZJ016248  train_features/ZJ016248.jpg  S0092              0.0   0.0    1.0   \n",
      "ZJ016482  train_features/ZJ016482.jpg  S0146              0.0   0.0    1.0   \n",
      "\n",
      "          civet_genet  hog  leopard  monkey_prosimian  rodent           labels  \n",
      "id                                                                              \n",
      "ZJ006365          1.0  0.0      0.0               0.0     0.0      civet_genet  \n",
      "ZJ008401          0.0  0.0      0.0               0.0     0.0            blank  \n",
      "ZJ015840          0.0  0.0      1.0               0.0     0.0          leopard  \n",
      "ZJ004201          0.0  0.0      0.0               0.0     1.0           rodent  \n",
      "ZJ014267          0.0  0.0      0.0               0.0     0.0  antelope_duiker  \n",
      "...               ...  ...      ...               ...     ...              ...  \n",
      "ZJ015318          0.0  0.0      0.0               0.0     1.0           rodent  \n",
      "ZJ015363          0.0  0.0      1.0               0.0     0.0          leopard  \n",
      "ZJ015565          0.0  0.0      0.0               0.0     0.0             bird  \n",
      "ZJ016248          0.0  0.0      0.0               0.0     0.0            blank  \n",
      "ZJ016482          0.0  0.0      0.0               0.0     0.0            blank  \n",
      "\n",
      "[2460 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge the two datasets for training set\n",
    "merged_train = pd.merge(train_X, train_Y, on='id')\n",
    "\n",
    "# Check if 'id' is in columns\n",
    "if 'id' in merged_train.columns:\n",
    "    # Set \"id\" as the index column\n",
    "    merged_train.set_index(\"id\", inplace = True) \n",
    "else:\n",
    "    print(\"Column 'id' does not exist in merged_train\")\n",
    "\n",
    "# Convert multi-label columns into a single column, so that this column tells us what animal type the row is \n",
    "merged_train['labels'] = merged_train.apply(lambda row: ' '.join([col for col in merged_train.columns[2:] if row[col]==1]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do the same thing for the validation set\n",
    "\n",
    "# Merge the two datasets\n",
    "merged_valid = pd.merge(valid_X, valid_Y, on='id')\n",
    "\n",
    "# Check if 'id' is in columns\n",
    "if 'id' in merged_valid.columns:\n",
    "    # Set \"id\" as the index column\n",
    "    merged_valid.set_index(\"id\", inplace = True) \n",
    "else:\n",
    "    print(\"Column 'id' does not exist in merged_train\")\n",
    "\n",
    "# Convert multi-label columns into a single column, so that this column tells us what animal type the row is \n",
    "merged_valid['labels'] = merged_valid.apply(lambda row: ' '.join([col for col in merged_valid.columns[2:] if row[col]==1]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do the same thing for the test set\n",
    "\n",
    "# Merge the two datasets\n",
    "merged_test = pd.merge(test_X, test_Y, on='id')\n",
    "\n",
    "# Check if 'id' is in columns\n",
    "if 'id' in merged_test.columns:\n",
    "    # Set \"id\" as the index column\n",
    "    merged_test.set_index(\"id\", inplace = True) \n",
    "else:\n",
    "    print(\"Column 'id' does not exist in merged_train\")\n",
    "\n",
    "\n",
    "# Convert multi-label columns into a single column, so that this column tells us what animal type the row is \n",
    "merged_test['labels'] = merged_test.apply(lambda row: ' '.join([col for col in merged_test.columns[2:] if row[col]==1]), axis=1)\n",
    "\n",
    "print(merged_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn train-valid-test sets into TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 'blank' is mapped to integer: 0\n",
      "Label 'monkey_prosimian' is mapped to integer: 1\n",
      "Label 'civet_genet' is mapped to integer: 2\n",
      "Label 'rodent' is mapped to integer: 3\n",
      "Label 'antelope_duiker' is mapped to integer: 4\n",
      "Label 'hog' is mapped to integer: 5\n",
      "Label 'bird' is mapped to integer: 6\n",
      "Label 'leopard' is mapped to integer: 7\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping of labels to integers\n",
    "unique_labels = merged_train['labels'].unique()\n",
    "label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Adding an integer label column to each DataFrame\n",
    "merged_train['label_int'] = merged_train['labels'].map(label_to_int)\n",
    "merged_valid['label_int'] = merged_valid['labels'].map(label_to_int)\n",
    "merged_test['label_int'] = merged_test['labels'].map(label_to_int)\n",
    "\n",
    "\n",
    "# Display the label to integer mapping\n",
    "for label, int_value in label_to_int.items():\n",
    "    print(f\"Label '{label}' is mapped to integer: {int_value}\")\n",
    "\n",
    "# Label 'blank' is mapped to integer: 0\n",
    "# Label 'monkey_prosimian' is mapped to integer: 1\n",
    "# Label 'civet_genet' is mapped to integer: 2\n",
    "# Label 'rodent' is mapped to integer: 3\n",
    "# Label 'antelope_duiker' is mapped to integer: 4\n",
    "# Label 'hog' is mapped to integer: 5\n",
    "# Label 'bird' is mapped to integer: 6\n",
    "# Label 'leopard' is mapped to integer: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import io\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(image, label):\n",
    "    # One-hot encode the label\n",
    "    label_one_hot = tf.one_hot(label, depth=8)  # Assuming 8 classes for one hot encoding\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'label': _bytes_feature(label_one_hot.numpy().tobytes())\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "# def serialize_example(image, label):\n",
    "#     feature = {\n",
    "#         'image': _bytes_feature(image),\n",
    "#         'label': _int64_feature(label)\n",
    "#     }\n",
    "#     example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#     return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 11:50:19.825255: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:20.465080: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:20.465140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:20.470810: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:20.471196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:20.471233: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:21.208676: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:21.208929: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:21.208951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-10 11:50:21.209038: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-10 11:50:21.209144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5535 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def create_tfrecord(df, filename):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for _, row in df.iterrows():\n",
    "            label = row['label_int']\n",
    "            image_path = row['filepath']\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize((224, 224))  # Resize if needed\n",
    "            image_bytes = io.BytesIO()\n",
    "            image.save(image_bytes, format='JPEG') # change JPEG to other file types if you want to do tfrecord on other file types\n",
    "            serialized_example = serialize_example(image_bytes.getvalue(), label)\n",
    "            writer.write(serialized_example)\n",
    "\n",
    "# Example usage\n",
    "create_tfrecord(merged_train, 'train.tfrecord')\n",
    "create_tfrecord(merged_valid, 'valid.tfrecord')\n",
    "create_tfrecord(merged_test, 'test.tfrecord')\n",
    "\n",
    "# 2 min and 46 seconds before I did the one-hot-encoding\n",
    "\n",
    "# took 4 min and 14 seconds after I did one-hot-encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _parse_function(proto):\n",
    "#     feature_description = {\n",
    "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
    "#         'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     }\n",
    "#     parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
    "#     image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "#     image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "#     label = tf.cast(parsed_features['label'], tf.int32)\n",
    "#     return image, label\n",
    "\n",
    "def _parse_function(proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Decode the one-hot encoded label\n",
    "    label = tf.io.decode_raw(parsed_features['label'], tf.float32)\n",
    "    label = tf.reshape(label, [8])  # Reshape to the number of classes, to adjust for one hot encoding\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(filename, batch_size):\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Example usage\n",
    "BATCH_SIZE = 128  # Adjust batch size as needed\n",
    "train_dataset = load_dataset('train.tfrecord', BATCH_SIZE)\n",
    "valid_dataset = load_dataset('valid.tfrecord', BATCH_SIZE)\n",
    "test_dataset = load_dataset('test.tfrecord', BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn test set (actual test set, not from the split) into TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_test_example(image):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_tfrecord(df, filename):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for _, row in df.iterrows():\n",
    "            image_path = row['filepath']\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize((224, 224))  # Resize if needed\n",
    "            image_bytes = io.BytesIO()\n",
    "            image.save(image_bytes, format='JPEG') # change JPEG to other file types if you want to do tfrecord on other file types\n",
    "            serialized_example = serialize_test_example(image_bytes.getvalue())\n",
    "            writer.write(serialized_example)\n",
    "\n",
    "# Usage\n",
    "create_test_tfrecord(test_values, 'test_values.tfrecord')\n",
    "\n",
    "# 46 seconds before one hot encoding\n",
    "\n",
    "# 44.5 seconds after doing one hot encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_test_function(proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_test_dataset(filename, batch_size):\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "    dataset = dataset.map(_parse_test_function)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Example usage for test data\n",
    "test_values_dataset = load_test_dataset('test_values.tfrecord', BATCH_SIZE) # the batch size variable is determined from the load_dataset() of the train-valid-test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Keras ImageDataGenerator() on Train/Test split\n",
    "The ImageDataGenerator not only helps you load images from the disk but also allows you to perform **data augmentation**, which is a technique to increase the diversity of your training set by applying random transformations (like rotation, zoom, flips, etc.) to the images. This is very useful to prevent overfitting and helps the model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # Creating an instance of the ImageDataGenerator for data augmentation and preprocessing\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "#     #preprocessing_function = custom_resize,  # call the crop function on each image\n",
    "\n",
    "#     # rotation_range=20,  # Up to 20 degrees of rotation\n",
    "#     # brightness_range=[0.8, 1.2],  # Adjust brightness by 20%\n",
    "#     # horizontal_flip=True,  # Horizontal flip\n",
    "#     # fill_mode='nearest' # The value \"nearest\" for fill_mode means that any empty space will be filled with the nearest pixel values. In other words, it copies the value of the nearest border pixel to fill the gap. \n",
    "# )\n",
    "\n",
    "# valid_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "#     #preprocessing_function = custom_resize,  # call the crop function on each image\n",
    "\n",
    "\n",
    "#     # You not supposed to do data augmetation on valid data, to replicate real life data. The only data augmentation should be resizing\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "#     #preprocessing_function = custom_resize,  # call the crop function on each image\n",
    "\n",
    "\n",
    "#     # You not supposed to do data augmetation on test data, to replicate real life data. The only data augmentation should be resizing\n",
    "# )\n",
    "\n",
    "# # Flow from dataframe method to load images using the dataframe\n",
    "\n",
    "# train_split_generator = train_datagen.flow_from_dataframe(\n",
    "#     dataframe=merged_train,\n",
    "#     x_col='filepath',\n",
    "#     y_col='labels',\n",
    "#     target_size=(224, 224),  # automatically resizes so no need for custom resize. When I did custom resize, it made my model worse\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=32,\n",
    "#     shuffle=True, #It's good to set it true so for each epoch, the order is changed and there is some variation between each epoch\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# valid_split_generator = valid_datagen.flow_from_dataframe(\n",
    "#     dataframe=merged_valid,\n",
    "#     x_col='filepath',\n",
    "#     y_col='labels',\n",
    "#     target_size=(224, 224),  # automatically resizes so no need for custom resize. When I did custom resize, it made my model worse\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=32,\n",
    "#     shuffle=False, # it's good to set it to false. you typically want to evaluate your model's performance on specific, fixed sets of data for validation and test stages.\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# test_split_generator = test_datagen.flow_from_dataframe(\n",
    "#     dataframe=merged_test, \n",
    "#     x_col='filepath',\n",
    "#     y_col='labels',\n",
    "#     target_size=(224, 224), # automatically resizes so no need for custom resize. When I did custom resize, it made my model worse\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=32,\n",
    "#     shuffle=False, # it's good to set it to false. you typically want to evaluate your model's performance on specific, fixed sets of data for validation and test stages.\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Keras ImageDataGenerator() on my test data (from test_values.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "#     #preprocessing_function = custom_resize,  # call the crop function on each image\n",
    "\n",
    "\n",
    "#     # You not supposed to do data augmetation on test data, to replicate real life data. The only data augmentation should be resizing\n",
    "# )\n",
    "\n",
    "# # Flow from dataframe method to load images using the dataframe\n",
    "\n",
    "\n",
    "# test_original_generator = test_datagen.flow_from_dataframe(\n",
    "#     dataframe=test_values, \n",
    "#     x_col='filepath',\n",
    "#     #y_col='', # The actual test data has no labels\n",
    "#     target_size=(224, 224),   # automatically resizes so no need for custom resize. When I did custom resize, it made my model worse\n",
    "#     color_mode='rgb',\n",
    "#     class_mode= None, # The actual test data has no labels\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Development:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 11:54:31.849957: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-02-10 11:54:34.305491: I external/local_xla/xla/service/service.cc:168] XLA service 0x559c926f2e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-10 11:54:34.305536: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-02-10 11:54:34.319908: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707584074.497696   13117 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 41s 372ms/step - loss: 2.0122 - accuracy: 0.2244 - categorical_crossentropy: 2.0122 - val_loss: 2.0248 - val_accuracy: 0.1802 - val_categorical_crossentropy: 2.0248\n",
      "Epoch 2/3\n",
      "91/91 [==============================] - 31s 346ms/step - loss: 1.8581 - accuracy: 0.2828 - categorical_crossentropy: 1.8581 - val_loss: 1.8867 - val_accuracy: 0.2200 - val_categorical_crossentropy: 1.8867\n",
      "Epoch 3/3\n",
      "91/91 [==============================] - 30s 332ms/step - loss: 1.7958 - accuracy: 0.3013 - categorical_crossentropy: 1.7958 - val_loss: 1.8919 - val_accuracy: 0.2440 - val_categorical_crossentropy: 1.8919\n",
      "35/35 [==============================] - 11s 306ms/step\n",
      "Successfully submitted!\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Load pre-trained ResNet50 model without the top layer\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Freeze the layers of the base model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# x = base_model.output # This line gets the output of the base_model (ResNet50 without the top layer) and uses it as the starting point for adding new layers.\n",
    "# x = GlobalAveragePooling2D()(x)  # Add a global spatial average pooling layer\n",
    "# x = Dense(818, activation='relu')(x)  # Add a fully-connected layer\n",
    "# predictions = Dense(8, activation='softmax')(x)  # Add a final output layer\n",
    "\n",
    "# # This is the model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions) # this model links the ResNetModel and the new layers to the prediction layer\n",
    "\n",
    "\n",
    "# #Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0016083950500646795),\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy', 'categorical_crossentropy'])\n",
    "\n",
    "\n",
    "# # fit model\n",
    "# model.fit(train_dataset, epochs=3, validation_data=valid_dataset)\n",
    "\n",
    "\n",
    "# # # Evaluate the model on the test dataset\n",
    "# # loss, accuracy, categorical_crossentropy = model.evaluate(test_dataset)\n",
    "\n",
    "# # print(\"Test Loss: \", loss)\n",
    "# # print(\"Test Accuracy: \", accuracy)\n",
    "# # print(\"Test Categorical Crossentropy: \", categorical_crossentropy)\n",
    "\n",
    "# # create predictions\n",
    "# predictions = model.predict(test_values_dataset)\n",
    "\n",
    "# # Assuming 'test_values' DataFrame has an 'id' column and is in the same order as 'test_values_dataset'\n",
    "# prediction_df = pd.DataFrame(predictions, columns=['blank', 'monkey_prosimian', 'civet_genet', 'rodent', 'antelope_duiker', 'hog', 'bird', 'leopard']) # make sure the column order matches the order of the tfrecord\n",
    "\n",
    "# # Insert the 'id' column\n",
    "# prediction_df.insert(0, 'id', test_values['id'].values)\n",
    "\n",
    "# # Ensure 'id' is the first column\n",
    "# prediction_df = prediction_df[['id'] + [col for col in prediction_df.columns if col != 'id']]\n",
    "\n",
    "# # Define the new order of the columns\n",
    "# new_order = ['id', 'antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent'] \n",
    "\n",
    "# # Reorder the columns\n",
    "# prediction_df = prediction_df.reindex(columns=new_order) # reorder the columns since that's how the drivendata competition wants it\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# prediction_df.to_csv('submission_ResNet50_test.csv', index=False) # make sure to change file name to represent the model number\n",
    "# print(\"Successfully submitted!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna with mySQL and also make it focus on minimizing log loss instead of maximizing accuracy (since the competition ranks us on log loss, not accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# pip install these if you haven't already. these are important for running mySQL with Optuna\n",
    "\n",
    "# %pip install mysql-connector-python \n",
    "# %pip install PyMySQL\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    with strategy.scope(): # This is for making sure you use the TPU since strategey was initialized at the start of the notebook for the TPU\n",
    "    \n",
    "        # Load the base pretrained model\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # weights = 'imagenet' means that it's using pretrained weights. include_top determines whether or not the fully-connected output layers of the model should be included.\n",
    "        # If include_top=False, the full model is loaded except for the output layers. This is useful if you want to fine-tune the model on a different task. By excluding the top layers, you can add your own output layers that are appropriate for your task.\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add a new top layer\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(trial.suggest_int('units', 32, 1024), activation='relu')(x)\n",
    "        predictions = Dense(8, activation='softmax')(x)\n",
    "\n",
    "        # This is the model we will train\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(learning_rate=trial.suggest_float('lr', 1e-4, 1e-2, log=True)),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        \n",
    "    # Train the model\n",
    "    model.fit(train_dataset, validation_data=valid_dataset, epochs=100, verbose = 1) # verbose = 0 will not display the progress bar\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    return score[0]  # Return validation loss\n",
    "\n",
    "\n",
    "# Replace the following with your actual username, password, host, and database name. And maybe use \"127.0.0.1\" instead of localhost if it doesn't work\n",
    "# optuna_storage = 'mysql+pymysql://optuna_user:your_password@localhost/database'. And maybe use \"127.0.0.1\" instead of localhost if it doesn't work\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load variables from .env\n",
    "db_password = os.getenv('DB_PASSWORD') # This is the azure password, stored in the secrets\n",
    "\n",
    "optuna_storage = f'mysql+pymysql://MichaelAzure:{db_password}@kaggle-third-sql.mysql.database.azure.com/kaggle_first_database?ssl_ca=/kaggle/input/certification&ssl_verify_cert=true'\n",
    "\n",
    "study = optuna.create_study(study_name='tpu_1', # name of the study\n",
    "                            storage=optuna_storage,  # URL for the mySQL schema\n",
    "                            direction='minimize', # maximize the log loss\n",
    "                            load_if_exists=True, # makes it so that if the study_name already exists in the schema, then it will append the new trials with the old trials and essentially resume the study. It will also remember the previous trials so it really is resuming the study\n",
    "                            )\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# you can access study trials info \n",
    "# study.trials_dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another thing to possibly try is to pick an even smaller 16:9 aspect ratio so that there is little to none upsampling (making images larger) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

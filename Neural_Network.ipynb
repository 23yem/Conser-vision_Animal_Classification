{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to my notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default code from Kaggle Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "   \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying some important libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 13:15:21.088632: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 13:15:21.156605: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 13:15:21.156676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 13:15:21.164179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 13:15:21.195276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 13:15:21.898839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: 2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4821/2944158885.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kerastuner: 1.0.5\n",
      "keras_tuner: 1.3.5\n",
      "Python: 3.10.12\n",
      "numpy: 1.24.3\n",
      "pandas: 2.1.4\n",
      "sklearn version: 1.2.2\n",
      "sklearn path: ['/home/michaelye22/.local/lib/python3.10/site-packages/sklearn']\n",
      "matplotlib: 3.8.2\n",
      "seaborn: 0.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow:\", tf.__version__)\n",
    "\n",
    "import kerastuner as kt\n",
    "print(\"kerastuner:\", kt.__version__)\n",
    "\n",
    "import keras_tuner as kt2\n",
    "print(\"keras_tuner:\", kt2.__version__)\n",
    "\n",
    "import platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "\n",
    "import numpy as np\n",
    "print(\"numpy:\", np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas:\", pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"sklearn version:\", sklearn.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(\"sklearn path:\", sklearn.__path__)\n",
    "\n",
    "import matplotlib\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "\n",
    "import seaborn as sns\n",
    "print(\"seaborn:\", sns.__version__)\n",
    "\n",
    "# On WSL\n",
    "\n",
    "# 2024-01-30 11:17:52.768682: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
    "# 2024-01-30 11:17:53.149956: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "# 2024-01-30 11:17:53.150001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "# 2024-01-30 11:17:53.210606: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "# 2024-01-30 11:17:53.339576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "# To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "# 2024-01-30 11:17:54.568146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "# Tensorflow: 2.15.0\n",
    "# /tmp/ipykernel_3814/2917868046.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
    "#   import kerastuner as kt\n",
    "# kerastuner: 1.0.5\n",
    "# keras_tuner: 1.3.5\n",
    "# Python: 3.10.12\n",
    "# numpy: 1.24.3\n",
    "# pandas: 2.1.4\n",
    "# sklearn version: 1.2.2\n",
    "# sklearn path: ['/home/michaelye22/.local/lib/python3.10/site-packages/sklearn']\n",
    "# matplotlib: 3.8.2\n",
    "# seaborn: 0.13.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global random seed to make sure we can replicate any model that we create (no randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_values are the features (X), and train_labels is the target/label (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"train_features.csv\")\n",
    "train_y = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "test_values = pd.read_csv(\"test_features.csv\")\n",
    "\n",
    "# print(\"train labels:\\n\", train_Y.head())\n",
    "\n",
    "# print(\"train values:\\n\", train_X.head())\n",
    "      \n",
    "# print(\"test_values:\\n\", test_values.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if there are any missing values in the data. If so, we have to do imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in train_X: 0\n",
      "Number of missing values in train_Y: 0\n",
      "Number of missing values in test_values: 0\n"
     ]
    }
   ],
   "source": [
    "missing_train_X = train_X.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_X:\", missing_train_X)\n",
    "\n",
    "missing_train_y = train_y.isnull().sum().sum()\n",
    "print(\"Number of missing values in train_Y:\", missing_train_y)\n",
    "\n",
    "missing_test_values = test_values.isnull().sum().sum()\n",
    "print(\"Number of missing values in test_values:\", missing_test_values )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 0 missing values in each dataframe, we don't have to do imputation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Train Distribution  Test Distribution\n",
      "site_animal                                                  \n",
      "S0001_bird                        0.000647           0.000728\n",
      "S0001_blank                       0.000404           0.000243\n",
      "S0001_leopard                     0.003073           0.003153\n",
      "S0001_monkey_prosimian            0.001051           0.000970\n",
      "S0002_bird                        0.000566           0.000485\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "\n",
    "train_features = train_X\n",
    "train_labels = train_y\n",
    "\n",
    "# Merge the datasets on 'id'\n",
    "merged_data = pd.merge(train_features, train_labels, on='id')\n",
    "\n",
    "# Identifying the animal present in each image and creating a combined category\n",
    "animal_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "merged_data['animal'] = merged_data[animal_columns].idxmax(axis=1)\n",
    "merged_data['site_animal'] = merged_data['site'] + '_' + merged_data['animal']\n",
    "\n",
    "# Checking the number of instances for each site_animal combination\n",
    "combination_counts = merged_data['site_animal'].value_counts()\n",
    "rare_combinations = combination_counts[combination_counts < 5]\n",
    "\n",
    "# Separating the dataset into common and rare combinations\n",
    "common_combinations = merged_data[~merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "rare_combinations_data = merged_data[merged_data['site_animal'].isin(rare_combinations.index)]\n",
    "\n",
    "# Stratified split for common combinations\n",
    "common_train_set, common_test_set = train_test_split(\n",
    "    common_combinations, test_size=0.25, stratify=common_combinations['site_animal'], random_state=42)\n",
    "\n",
    "# Randomly splitting rare combinations\n",
    "total_samples = rare_combinations_data.shape[0]\n",
    "train_samples = int(np.round(total_samples * 0.75))\n",
    "rare_train_set = rare_combinations_data.sample(n=train_samples, random_state=42)\n",
    "rare_test_set = rare_combinations_data.drop(rare_train_set.index)\n",
    "\n",
    "# Combining the splits into final train and test sets\n",
    "final_train_set = pd.concat([common_train_set, rare_train_set])\n",
    "final_test_set = pd.concat([common_test_set, rare_test_set])\n",
    "\n",
    "# Optional: Verifying the final distribution (can be commented out for large datasets)\n",
    "final_train_distribution = final_train_set['site_animal'].value_counts(normalize=True)\n",
    "final_test_distribution = final_test_set['site_animal'].value_counts(normalize=True)\n",
    "final_distribution_summary = pd.DataFrame({\n",
    "    'Train Distribution': final_train_distribution,\n",
    "    'Test Distribution': final_test_distribution\n",
    "})\n",
    "print(final_distribution_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the 75/25 train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Proportion: 74.99%\n",
      "Test Set Proportion: 25.01%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of samples in each set\n",
    "num_train_samples = final_train_set.shape[0]\n",
    "num_test_samples = final_test_set.shape[0]\n",
    "total_samples = num_train_samples + num_test_samples\n",
    "\n",
    "# Calculate the proportions\n",
    "train_proportion = num_train_samples / total_samples\n",
    "test_proportion = num_test_samples / total_samples\n",
    "\n",
    "# Print out the proportions\n",
    "print(\"Training Set Proportion: {:.2%}\".format(train_proportion))\n",
    "print(\"Test Set Proportion: {:.2%}\".format(test_proportion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure that train and test set have a 75/25 split for each site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for each site, around 75% should be in the training data and around 25% should be in the test data. This ensures niether the train or test set have a unbalanced amount of a certain site, leading to bias and bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of each site in both sets\n",
    "site_counts_train = final_train_set['site'].value_counts()\n",
    "site_counts_test = final_test_set['site'].value_counts()\n",
    "\n",
    "# Combine the counts into a single DataFrame for comparison\n",
    "combined_site_counts = pd.DataFrame({'Train Count': site_counts_train, 'Test Count': site_counts_test})\n",
    "\n",
    "# Calculate the total counts for each site\n",
    "combined_site_counts['Total Count'] = combined_site_counts['Train Count'] + combined_site_counts['Test Count']\n",
    "\n",
    "# Calculate the percentage split for each site\n",
    "combined_site_counts['Train Percentage'] = (combined_site_counts['Train Count'] / combined_site_counts['Total Count']) * 100\n",
    "combined_site_counts['Test Percentage'] = (combined_site_counts['Test Count'] / combined_site_counts['Total Count']) * 100\n",
    "\n",
    "# Display the combined counts with percentage split\n",
    "#print(combined_site_counts.head())\n",
    "combined_site_counts.to_csv(\"site_percentage_check.csv\")\n",
    "\n",
    "# Check to see if there any rows of data with a train percentage below 70 or above 80 (the ideal is 75)\n",
    "filtered_df = combined_site_counts[(combined_site_counts['Train Percentage'] < 70) | (combined_site_counts['Train Percentage'] > 80)]\n",
    "#print(filtered_df)\n",
    "#print(len(filtered_df)) # There are only 13 sites which have a bad train/test split, but they all side more towards the train set, which is good\n",
    "\n",
    "\n",
    "#print(len(final_train_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 13 sites which have a bad train/test split, but they all side more towards the train set, which is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure the trian and test set have the 75/25 split for each animal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, for each animal, around 75% should be in the training data and around 25% should be in the test data. This ensures neither the train or test set have a unbalanced amount of a certain animal, leading to bias and bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label columns\n",
    "label_columns = ['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n",
    "\n",
    "# Calculate the count of each label in both sets\n",
    "label_counts_train = final_train_set[label_columns].sum()\n",
    "label_counts_test = final_test_set[label_columns].sum()\n",
    "\n",
    "# Combine the counts into a single DataFrame for comparison\n",
    "combined_label_counts = pd.DataFrame({'Train Count': label_counts_train, 'Test Count': label_counts_test})\n",
    "\n",
    "# Calculate the total counts for each label\n",
    "combined_label_counts['Total Count'] = combined_label_counts['Train Count'] + combined_label_counts['Test Count']\n",
    "\n",
    "# Calculate the percentage split for each label\n",
    "combined_label_counts['Train Percentage'] = (combined_label_counts['Train Count'] / combined_label_counts['Total Count']) * 100\n",
    "combined_label_counts['Test Percentage'] = (combined_label_counts['Test Count'] / combined_label_counts['Total Count']) * 100\n",
    "\n",
    "# Display the combined counts with percentage split\n",
    "#print(combined_label_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each class has around a 75/25 split for train and test split, my data looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the data to include only the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(final_train_set)\n",
    "\n",
    "# Remove all the new features that I created for the stratified train_test split\n",
    "train_X = final_train_set[['id', 'filepath', 'site']]\n",
    "train_Y = final_train_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "test_X = final_test_set[['id', 'filepath', 'site']]\n",
    "test_Y = final_test_set[['id','antelope_duiker','bird','blank','civet_genet','hog','leopard','monkey_prosimian','rodent']]\n",
    "\n",
    "\n",
    "# Make \"id\" the index column\n",
    "train_X.set_index('id', inplace=True) # inplace = True means that it edits the original dataframe, and no new dataframe is created\n",
    "train_Y.set_index('id', inplace=True)\n",
    "\n",
    "test_X.set_index('id', inplace=True)\n",
    "test_Y.set_index('id', inplace=True)\n",
    "\n",
    "#print(test_Y)\n",
    "\n",
    "\n",
    "#print(train_X)\n",
    "#print(train_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it so that if there already exists a dataset for train_X, train_Y, and test_X, then we will use those (so that each of my models are trained on the same data, making them deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used old directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('train_split_X.csv'):\n",
    "    print(\"create new directory\")\n",
    "    train_X.to_csv('train_split_X.csv')\n",
    "    train_Y.to_csv('train_split_Y.csv')\n",
    "    test_X.to_csv('test_split_X.csv')\n",
    "    test_Y.to_csv('test_split_Y.csv')\n",
    "\n",
    "else:\n",
    "    print(\"used old directory\")\n",
    "    train_X = pd.read_csv('train_split_X.csv')\n",
    "    train_Y = pd.read_csv('train_split_Y.csv')\n",
    "    test_X = pd.read_csv('test_split_X.csv')\n",
    "    test_Y = pd.read_csv(\"test_split_Y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if each image has the same dimensions since that's important for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# def check_image_dimensions(directory):\n",
    "#     image_sizes = {}\n",
    "#     for img_name in os.listdir(directory):\n",
    "#         if not img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')): # now also checks for .tif\n",
    "#             continue\n",
    "#         img_path = os.path.join(directory, img_name)\n",
    "#         with Image.open(img_path) as img:\n",
    "#             # Get image size\n",
    "#             size = img.size\n",
    "#             if size in image_sizes:\n",
    "#                 image_sizes[size] += 1\n",
    "#             else:\n",
    "#                 image_sizes[size] = 1\n",
    "\n",
    "#     for size, count in image_sizes.items():\n",
    "#         print(f\"For the {directory} directory, {count} images are of dimension {size}\")\n",
    "\n",
    "# # Use it on the train and test data only if this code segment was never ran in this coding session:\n",
    "\n",
    "# # Use it on the train and test data:\n",
    "# check_image_dimensions('train_features')\n",
    "# check_image_dimensions('test_features')\n",
    "\n",
    "\n",
    "# # # For the train_features directory, different dimensions found: {(160, 120), (960, 515), (640, 335), (960, 540), (640, 360), (360, 215), (160, 95), (360, 240)}\n",
    "# # # For the test_features directory, different dimensions found: {(960, 515), (160, 120), (640, 335), (960, 540), (320, 215), (640, 360), (360, 240), (320, 240)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing all the images to (640, 360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know the main sizes are (960, 540) and (640, 360). LUCKILY, they both close to a 16:9 aspect ratio, so both are viable options. However, it is generally better to shrink than to enlarge, so I'm choosing (640, 360).\n",
    "\n",
    "Another thing to possibly try is to pick an even smaller 16:9 aspect ratio so that there is little to none upsampling (making images larger) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will actually make the resizing function when I use the ImageDataGenertor. \n",
    "# By calling the resize function in the ImageDataGenerator, I won't have to save my images in my local folder and waste space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before I use ImageDataGenerator, I have to format my dataframes so that they are able to be read properly by ImageDataGenertor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multi-class problem so data format has to be modified so that it can be handled by ImageDataGenerator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             filepath   site  antelope_duiker  bird  blank  \\\n",
      "id                                                                           \n",
      "ZJ000805  train_features/ZJ000805.jpg  S0147              0.0   0.0    0.0   \n",
      "ZJ008873  train_features/ZJ008873.jpg  S0156              0.0   0.0    0.0   \n",
      "ZJ002713  train_features/ZJ002713.jpg  S0136              0.0   0.0    0.0   \n",
      "ZJ001535  train_features/ZJ001535.jpg  S0185              0.0   0.0    0.0   \n",
      "ZJ006090  train_features/ZJ006090.jpg  S0060              0.0   0.0    0.0   \n",
      "...                               ...    ...              ...   ...    ...   \n",
      "ZJ000736  train_features/ZJ000736.jpg  S0028              0.0   0.0    0.0   \n",
      "ZJ002549  train_features/ZJ002549.jpg  S0173              0.0   0.0    0.0   \n",
      "ZJ004619  train_features/ZJ004619.jpg  S0182              1.0   0.0    0.0   \n",
      "ZJ014485  train_features/ZJ014485.jpg  S0027              1.0   0.0    0.0   \n",
      "ZJ015318  train_features/ZJ015318.jpg  S0134              0.0   0.0    0.0   \n",
      "\n",
      "          civet_genet  hog  leopard  monkey_prosimian  rodent  \\\n",
      "id                                                              \n",
      "ZJ000805          0.0  0.0      0.0               0.0     1.0   \n",
      "ZJ008873          0.0  1.0      0.0               0.0     0.0   \n",
      "ZJ002713          0.0  0.0      0.0               1.0     0.0   \n",
      "ZJ001535          0.0  0.0      1.0               0.0     0.0   \n",
      "ZJ006090          1.0  0.0      0.0               0.0     0.0   \n",
      "...               ...  ...      ...               ...     ...   \n",
      "ZJ000736          0.0  1.0      0.0               0.0     0.0   \n",
      "ZJ002549          0.0  1.0      0.0               0.0     0.0   \n",
      "ZJ004619          0.0  0.0      0.0               0.0     0.0   \n",
      "ZJ014485          0.0  0.0      0.0               0.0     0.0   \n",
      "ZJ015318          0.0  0.0      0.0               0.0     1.0   \n",
      "\n",
      "                    labels  \n",
      "id                          \n",
      "ZJ000805            rodent  \n",
      "ZJ008873               hog  \n",
      "ZJ002713  monkey_prosimian  \n",
      "ZJ001535           leopard  \n",
      "ZJ006090       civet_genet  \n",
      "...                    ...  \n",
      "ZJ000736               hog  \n",
      "ZJ002549               hog  \n",
      "ZJ004619   antelope_duiker  \n",
      "ZJ014485   antelope_duiker  \n",
      "ZJ015318            rodent  \n",
      "\n",
      "[12365 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1 and df2 are your two dataframes\n",
    "merged_df = pd.merge(train_X, train_Y, on='id')\n",
    "\n",
    "merged_df.set_index(\"id\", inplace = True) # inplace = True means that it edits the original dataframe, and no new dataframe is created\n",
    "\n",
    "# Convert multi-label columns into a single column, so that this column tells us what animal type the row is \n",
    "merged_df['labels'] = merged_df.apply(lambda row: ' '.join([col for col in merged_df.columns[2:] if row[col]==1]), axis=1)\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Keras ImageDataGenerator() on Train/Test split\n",
    "The ImageDataGenerator not only helps you load images from the disk but also allows you to perform **data augmentation**, which is a technique to increase the diversity of your training set by applying random transformations (like rotation, zoom, flips, etc.) to the images. This is very useful to prevent overfitting and helps the model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# def custom_resize(image, target_size=(640, 360)):\n",
    "#     # Convert the input NumPy array image to a PIL Image\n",
    "#     img = Image.fromarray(image)\n",
    "\n",
    "#     # Resize the image\n",
    "#     img_resized = img.resize(target_size, Image.ANTIALIAS)\n",
    "\n",
    "#     # Convert back to NumPy array and return\n",
    "#     return np.array(img_resized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Creating an instance of the ImageDataGenerator for data augmentation and preprocessing\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,  # Rescale the image pixel values to [0,1]\n",
    "#     preprocessing_function = custom_resize  # call the crop function on each image\n",
    "\n",
    "#     # Potential data augmentation techniques that won't affect the 32x32px center\n",
    "#     #brightness_range=[0.8, 1.2], \n",
    "#     #channel_shift_range=20, \n",
    "\n",
    "#     # I removed these transformations for the data augmentation since this project involves detecting tumor tissue in the center 32x32px region so I can't be doing zooming and other transformations for this project specifically\n",
    "\n",
    "#     # rotation_range=40,  # Random rotations\n",
    "#     # width_shift_range=0.2,  # Random horizontal shifts\n",
    "#     # height_shift_range=0.2,  # Random vertical shifts\n",
    "#     # shear_range=0.2,  # Shear transformations\n",
    "#     # zoom_range=0.2,  # Random zoom\n",
    "#     # horizontal_flip=True,  # Random horizontal flips\n",
    "#     # fill_mode='nearest'  # Strategy for filling in new pixels\n",
    "# )\n",
    "\n",
    "# val_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = custom_resize)  # call the crop function on each image\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = custom_resize) # call the crop function on each image\n",
    "\n",
    "\n",
    "\n",
    "# # Flow from dataframe method to load images using the dataframe\n",
    "\n",
    "# train_generator = train_datagen.flow_from_dataframe(\n",
    "#     dataframe=merged_df,\n",
    "#     x_col='filepath',\n",
    "#     y_col='labels',\n",
    "#     target_size=(640, 360),\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=32,\n",
    "#     shuffle=True,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# val_generator = val_datagen.flow_from_dataframe(\n",
    "#     dataframe=val_df, # Use the validation dataframe (with labels, id, and paths)\n",
    "#     x_col='path',\n",
    "#     y_col='label',\n",
    "#     target_size=(32, 32),\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='binary',\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# test_generator = test_datagen.flow_from_dataframe(\n",
    "#     dataframe=test_df, # Use the testing dataframe (with labels, id, and paths)\n",
    "#     x_col='path',\n",
    "#     y_col='label',\n",
    "#     target_size=(32, 32),\n",
    "#     color_mode='rgb',\n",
    "#     class_mode='binary',\n",
    "#     batch_size=32,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# # After setting this up, you can use train_generator as the input to the fit or fit_generator method of your Keras model, \n",
    "# # which will load images in batches and train your model on them.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another thing to possibly try is to pick an even smaller 16:9 aspect ratio so that there is little to none upsampling (making images larger) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
